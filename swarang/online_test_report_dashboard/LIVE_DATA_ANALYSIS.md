# Live Data Integration Analysis

## âœ… **YES, the code structure CAN be used for live data!**

The current architecture is **well-designed** and **ready for live data integration** with minimal changes.

---

## Current Architecture Assessment

### âœ… **What's Already Ready:**

1. **Flexible Data Structure**
   - Uses dictionaries (`dict`) for all data, making it adaptable to any data source
   - Pydantic models validate incoming data
   - Frontend handles dynamic data with optional chaining (`?.`)

2. **API Endpoints**
   - `/api/report` (POST) - Already accepts live data payloads âœ…
   - `/api/sample` (GET) - Currently uses static file (needs replacement)
   - `/api/report/latest` (GET) - Works with any generated PDF

3. **Error Handling**
   - Frontend has try-catch blocks
   - Backend validates data with Pydantic
   - Graceful fallbacks in place

4. **CORS Configuration**
   - Already configured for cross-origin requests
   - Ready for production deployment

---

## ðŸ”§ **What Needs to Change for Live Data:**

### 1. **Backend Changes (Required)**

#### Replace `/api/sample` endpoint:

**Current:**
```python
@app.get("/api/sample")
async def sample_data():
    with open("static_sample.json", "r") as f:
        sample = json.load(f)
    return JSONResponse(sample)
```

**Replace with:**
```python
@app.get("/api/report/{candidate_id}")
async def get_candidate_report(candidate_id: str):
    # Connect to your database
    # Fetch candidate data, MCQ results, coding results, proctoring data
    # Return in the same JSON structure
    pass
```

#### Add Database Connection:
- Connect to your database (PostgreSQL, MySQL, MongoDB, etc.)
- Query candidate exam results
- Format data to match existing structure

### 2. **Frontend Changes (Required)**

#### Update API endpoint:

**Current:**
```javascript
axios.get("http://localhost:8000/api/sample")
```

**Replace with:**
```javascript
// Option 1: Get candidate ID from URL params
const candidateId = new URLSearchParams(window.location.search).get('id');
axios.get(`http://localhost:8000/api/report/${candidateId}`)

// Option 2: Get from route params (if using React Router)
const { candidateId } = useParams();
axios.get(`http://localhost:8000/api/report/${candidateId}`)
```

#### Remove hardcoded fallback:
```javascript
// Remove this fallback data
setData({
  candidate: {name:"John Doe", ...},
  // ...
});
```

### 3. **Environment Configuration (Recommended)**

Create `.env` files for different environments:

**Backend `.env`:**
```env
DATABASE_URL=postgresql://user:pass@localhost/exam_db
API_BASE_URL=http://localhost:8000
```

**Frontend `.env`:**
```env
REACT_APP_API_URL=http://localhost:8000
```

---

## ðŸ“‹ **Data Structure Requirements**

Your live data source must return data in this format:

```json
{
  "candidate": {
    "name": "string",
    "email": "string",
    "id": "string",
    "exam": "string",
    "date": "string",
    "duration": "string"
  },
  "mcq": {
    "max_marks": number,
    "marks_obtained": number,
    "correct": number,
    "wrong": number,
    "questions": [
      {
        "id": number,
        "question": "string",
        "options": ["string"],
        "correct": "string",
        "given_answer": "string",
        "is_correct": boolean,
        "marks": number
      }
    ]
  },
  "coding": {
    "max_marks": number,
    "marks_obtained": number,
    "output_ok": boolean,
    "questions": [
      {
        "id": number,
        "title": "string",
        "description": "string",
        "difficulty": "string",
        "given_answer": "string",
        "marks": number,
        "test_cases_passed": number,
        "test_cases_total": number,
        "output_correct": boolean
      }
    ]
  },
  "proctoring": {
    "flagged_faces": number,
    "focus_deviation_percent": number,
    "cheating_events": number,
    "unusual_activity": "string"
  },
  "include_proctoring": boolean
}
```

---

## ðŸš€ **Implementation Steps**

### Step 1: Database Setup
1. Design/verify database schema matches data structure
2. Add database connection library (SQLAlchemy, PyMongo, etc.)
3. Create data access layer

### Step 2: Backend Integration
1. Replace `/api/sample` with `/api/report/{candidate_id}`
2. Add database queries
3. Transform database results to match JSON structure
4. Add error handling for missing records

### Step 3: Frontend Updates
1. Update API endpoint URL
2. Add candidate ID parameter handling
3. Remove hardcoded fallback
4. Add loading states for better UX

### Step 4: Testing
1. Test with real database data
2. Verify PDF generation works
3. Test error scenarios (missing data, invalid IDs)

---

## ðŸ”’ **Security Considerations**

1. **Authentication**
   - Add JWT tokens or session-based auth
   - Verify user has permission to view report

2. **Authorization**
   - Ensure candidates can only view their own reports
   - Admin/evaluator roles for viewing all reports

3. **Input Validation**
   - Validate candidate_id format
   - Sanitize all inputs
   - Rate limiting on API endpoints

4. **CORS**
   - Update `allow_origins` from `["*"]` to specific domains in production

---

## ðŸ“Š **Example Database Query (PostgreSQL)**

```python
from sqlalchemy.orm import Session

@app.get("/api/report/{candidate_id}")
async def get_candidate_report(candidate_id: str, db: Session = Depends(get_db)):
    # Fetch candidate
    candidate = db.query(Candidate).filter(Candidate.id == candidate_id).first()
    if not candidate:
        raise HTTPException(status_code=404, detail="Candidate not found")
    
    # Fetch exam results
    exam = db.query(Exam).filter(Exam.candidate_id == candidate_id).first()
    
    # Fetch MCQ answers
    mcq_answers = db.query(MCQAnswer).filter(MCQAnswer.exam_id == exam.id).all()
    
    # Fetch coding solutions
    coding_solutions = db.query(CodingSolution).filter(CodingSolution.exam_id == exam.id).all()
    
    # Fetch proctoring data
    proctoring = db.query(ProctoringData).filter(ProctoringData.exam_id == exam.id).first()
    
    # Transform to required format
    return {
        "candidate": {
            "name": candidate.name,
            "email": candidate.email,
            "id": candidate.id,
            "exam": exam.name,
            "date": exam.date,
            "duration": exam.duration
        },
        "mcq": {
            "max_marks": exam.mcq_max_marks,
            "marks_obtained": sum(a.marks for a in mcq_answers),
            "correct": sum(1 for a in mcq_answers if a.is_correct),
            "wrong": sum(1 for a in mcq_answers if not a.is_correct),
            "questions": [transform_mcq_answer(a) for a in mcq_answers]
        },
        "coding": {
            "max_marks": exam.coding_max_marks,
            "marks_obtained": sum(s.marks for s in coding_solutions),
            "output_ok": all(s.output_correct for s in coding_solutions),
            "questions": [transform_coding_solution(s) for s in coding_solutions]
        },
        "proctoring": {
            "flagged_faces": proctoring.flagged_faces if proctoring else 0,
            "focus_deviation_percent": proctoring.focus_deviation if proctoring else 0,
            "cheating_events": proctoring.cheating_events if proctoring else 0,
            "unusual_activity": proctoring.unusual_activity if proctoring else "None detected"
        }
    }
```

---

## âœ… **Summary**

**The code structure is 95% ready for live data!**

**What works:**
- âœ… Data structure is flexible
- âœ… PDF generation accepts any data
- âœ… Frontend handles dynamic data
- âœ… Error handling in place
- âœ… CORS configured

**What needs changes:**
- ðŸ”§ Replace `/api/sample` with database endpoint
- ðŸ”§ Update frontend API call
- ðŸ”§ Add database connection
- ðŸ”§ Add authentication (recommended)

**Estimated effort:** 2-4 hours for basic integration, 1-2 days for production-ready with auth.

---

## ðŸŽ¯ **Recommendation**

The architecture is **excellent** for live data integration. The separation of concerns (frontend, backend API, PDF generator) makes it easy to swap out the data source without major refactoring.

